"""
core/analytics.py
=================
Advanced Analytics Module for Food Safety Risk Scoring.
Implementation Level: Phase 3.1 (Statistical Stability & Safety Guards)
 - Config Refactoring
 - Small Sample Variance Guard
 - Early Month Velocity Guard
 - Conditional Safe Zone
"""

import numpy as np
import pandas as pd
from scipy.stats import poisson, nbinom
from typing import Dict, Tuple, List
import statsmodels.api as sm
from datetime import datetime
from dataclasses import dataclass

# --- 1. Configuration Management (Phase 3.1) ---
@dataclass
class RiskConfig:
    # Data Requirements
    MIN_DATA_POINTS: int = 3
    MIN_SAMPLE_FOR_NB: int = 6  # ìŒì´í•­ë¶„í¬ ì‚¬ìš©ì„ ìœ„í•œ ìµœì†Œ í‘œë³¸ ìˆ˜
    
    # Statistical Parameters
    EWMA_LAMBDA: float = 0.2
    NELSON_WINDOW_BIAS: int = 9
    NELSON_WINDOW_TREND: int = 6
    STL_MIN_PERIODS: int = 24
    
    # Scoring Weights
    SCORE_ACCIDENT: int = 100
    SCORE_CRITICAL_BONUS: int = 10
    
    SCORE_NELSON_DEV: int = 30   # ê´€ë¦¬ì´íƒˆ
    SCORE_NELSON_BIAS: int = 20  # í‰ê· ì´ë™
    SCORE_NELSON_TREND: int = 20 # ì§€ì†ìƒìŠ¹
    SCORE_MOMENTUM: int = 15     # ì—°ì†ìƒìŠ¹(3M)
    
    SCORE_PARTIAL_ABS: int = 30  # ì¡°ê¸°ê³¼ë‹¤
    SCORE_PARTIAL_VEL: int = 40  # ì†ë„ê¸‰ì¦
    SCORE_PARTIAL_WARN: int = 30 # ì†ë„ì£¼ì˜
    
    # Thresholds
    THRESHOLD_RED_CRIT: int = 75
    THRESHOLD_RED_GEN: int = 85
    THRESHOLD_YEL_CRIT: int = 50
    THRESHOLD_YEL_GEN: int = 60
    
    # Safety Guards
    MIN_PROGRESS_FOR_VELOCITY: float = 0.2  # ì›” ì§„í–‰ë¥  20% ì´ìƒì¼ ë•Œë§Œ ì†ë„ íŒì •

# Critical Grades Definition
CRITICAL_GRADES_SET = {'ì¤‘ëŒ€', 'ìœ„í—˜', 'ì‚¬ê³ '}

class RiskScoringEngine:
    def __init__(self, data_series: pd.Series, grade: str = None, target_month_str: str = None):
        self.series = data_series.sort_index()
        self.grade = grade
        self.is_critical = (grade in CRITICAL_GRADES_SET) if grade else False
        self.cfg = RiskConfig()
        
        # í˜„ì¬ ì›”(Partial Month) ì—¬ë¶€ í™•ì¸
        self.is_partial_month = False
        self.progress_ratio = 1.0
        
        if target_month_str:
            try:
                today = datetime.now()
                target_date = datetime.strptime(target_month_str, "%Y-%m")
                
                # ë¶„ì„ ëŒ€ìƒì´ 'ì´ë²ˆ ë‹¬'ì´ê³ , ì•„ì§ ë‹¬ì´ ì•ˆ ëë‚¬ë‹¤ë©´
                if (target_date.year == today.year) and (target_date.month == today.month):
                    self.is_partial_month = True
                    # ì§„í–‰ë¥  ê³„ì‚°
                    day_of_month = max(1, today.day)
                    days_in_month = (target_date.replace(month=target_date.month % 12 + 1, day=1) - pd.Timedelta(days=1)).day
                    self.progress_ratio = day_of_month / days_in_month
            except:
                pass 

        if len(self.series) > 0:
            self.current_value = self.series.iloc[-1]
            self.current_date = self.series.index[-1]
            self.history = self.series.iloc[:-1]
        else:
            self.current_value = 0
            self.history = pd.Series(dtype=float)
            
        self.n_obs = len(self.history)
        self.mean = self.history.mean() if self.n_obs > 0 else 0.0
        self.std = self.history.std() if self.n_obs > 1 else 0.0
        self.var = self.history.var() if self.n_obs > 1 else 0.0
        
        # [Regime] í¬ì†Œì„± íŒë‹¨
        zero_ratio = (self.history == 0).sum() / self.n_obs if self.n_obs > 0 else 0
        self.is_sparse = (self.mean < 1.0) or (zero_ratio > 0.5)

    def _calculate_sparse_score(self) -> Tuple[float, str]:
        """ [Track A] í¬ì†Œ ë°ì´í„° ìŠ¤ì½”ì–´ë§ (Phase 3.1: ì†Œí‘œë³¸ ê°€ë“œ ì¶”ê°€) """
        if self.mean == 0:
            raw_score = 100.0 if self.current_value > 0 else 0.0
            method = "í¬ì†Œìœ í˜• ëŒë°œ ë°œìƒ"
        else:
            # [Phase 3.1] Small Sample Variance Guard
            # í‘œë³¸ì´ ì ì„ ë•Œ(N<6) ë¶„ì‚° ì¶”ì •ì€ ë§¤ìš° ë¶ˆì•ˆì •í•˜ë¯€ë¡œ ë³´ìˆ˜ì ì¸ Poisson ê°•ì œ
            use_nbinom = False
            if self.n_obs >= self.cfg.MIN_SAMPLE_FOR_NB:
                # ê³¼ëŒ€ì‚°í¬ ê²€ì • (ë¶„ì‚°ì´ í‰ê· ì˜ 1.2ë°° ì´ˆê³¼)
                if self.var > (1.2 * self.mean):
                    use_nbinom = True
            
            if use_nbinom:
                p_est = self.mean / self.var
                r_est = (self.mean * p_est) / (1 - p_est)
                p_val = 1 - nbinom.cdf(self.current_value - 1, n=r_est, p=p_est)
                method = "ë¶„í¬ ì´íƒˆ"
            else:
                p_val = 1 - poisson.cdf(self.current_value - 1, mu=self.mean)
                method = "ë¶„í¬ ì´íƒˆ"

            if p_val < 1e-5: raw_score = 100.0
            else:
                raw_score = -np.log10(p_val) * 25
                raw_score = min(100.0, max(0.0, raw_score))

        return raw_score, method

    def _calculate_momentum_score(self) -> float:
        """ [Phase 3.0] ì—°ì† ìƒìŠ¹ ëª¨ë©˜í…€ """
        if self.n_obs < 2: return 0.0
        
        val_t = self.current_value
        val_t_1 = self.history.iloc[-1]
        val_t_2 = self.history.iloc[-2]
        
        if (val_t > val_t_1) and (val_t_1 > val_t_2):
            if val_t >= 3: 
                return self.cfg.SCORE_MOMENTUM
        return 0.0

    def _get_z_score_with_stl(self) -> Tuple[float, str]:
        """ [Track B] Z-Score (STL or Standard) """
        if self.n_obs >= self.cfg.STL_MIN_PERIODS and self.std > 0:
            try:
                decomposition = sm.tsa.seasonal_decompose(self.history, model='additive', period=12)
                residuals = decomposition.resid.dropna()
                resid_mean = residuals.mean()
                resid_std = residuals.std()
                
                last_trend = decomposition.trend.dropna().iloc[-1]
                seasonal_comp = decomposition.seasonal
                target_month_idx = self.current_date.month
                current_seasonal = seasonal_comp[seasonal_comp.index.month == target_month_idx].mean()
                
                expected_val = last_trend + current_seasonal
                current_resid = self.current_value - expected_val
                
                z = (current_resid - resid_mean) / (resid_std + 1e-6)
                return z, "ì •ìƒíŒ¨í„´ ì´íƒˆ"
            except:
                pass
        
        z = (self.current_value - self.mean) / (self.std + 1e-6)
        return z, "í‰ê·  ëŒ€ë¹„ ê¸‰ì¦"

    def _apply_nelson_rules(self, z_score: float) -> Tuple[float, List[str]]:
        triggered = []
        score_add = 0.0
        full = self.series
        
        # Adaptive Threshold (Phase 3.0)
        cv = (self.std / self.mean) if self.mean > 0 else 0
        base_limit = 2.5 if self.is_critical else 3.0
        
        if cv < 0.1 and self.mean > 1.0:
            limit_z = 2.0
            adaptive_msg = "(ì•ˆì •ê³µì •)"
        elif cv > 0.5:
            limit_z = 3.5
            adaptive_msg = "(ë¶ˆì•ˆì •ê³µì •)"
        else:
            limit_z = base_limit
            adaptive_msg = ""
            
        warn_z = max(1.5, limit_z - 1.0)
        
        # Rule 1: Limit Violation
        if abs(z_score) > limit_z:
            triggered.append(f"ì •ìƒë²”ìœ„ ì´íƒˆ")
            score_add += self.cfg.SCORE_NELSON_DEV
        elif abs(z_score) > warn_z:
            score_add += (self.cfg.SCORE_NELSON_DEV / 2)
            
        # Rule 2: Bias (Shift)
        if len(full) >= self.cfg.NELSON_WINDOW_BIAS:
            last_n = full.iloc[-self.cfg.NELSON_WINDOW_BIAS:]
            if (last_n > self.mean).all():
                triggered.append(f"ì§€ì†ì  ìƒìŠ¹ - {self.cfg.NELSON_WINDOW_BIAS}ê°œì›”")
                score_add += self.cfg.SCORE_NELSON_BIAS
        
        # Rule 3: Trend
        if len(full) >= self.cfg.NELSON_WINDOW_TREND:
            last_n = full.iloc[-self.cfg.NELSON_WINDOW_TREND:]
            diffs = last_n.diff().dropna()
            if (diffs > 0).all():
                triggered.append(f"ì§€ì†ì  ìƒìŠ¹ - ({self.cfg.NELSON_WINDOW_TREND}ê°œì›”)")
                score_add += self.cfg.SCORE_NELSON_TREND
                
        return score_add, triggered

    def calculate_score(self) -> Dict:
        # 0. ë°œìƒ ì—†ìŒ
        if self.current_value == 0:
            return {"score": 0, "status": "", "reason": "ë°œìƒ ì—†ìŒ"}

        # 1. ì›”ì¤‘ ì¡°ê¸° ê²½ë³´ (Partial Month Logic)
        partial_month_penalty = 0
        partial_reason = ""
        
        # ì¡°ê¸°ê³¼ë‹¤: 2ê±´ ì´ìƒì¼ ë•Œë§Œ íŒì •
        if self.is_partial_month and self.current_value > 1:
            # A. ì ˆëŒ€ ì†ë„ ìœ„ë°˜
            if self.current_value >= self.mean and self.mean > 0 and self.progress_ratio < 0.7:
                partial_month_penalty = self.cfg.SCORE_PARTIAL_ABS
                partial_reason = f"ìƒìŠ¹ì„¸ ê°€ì†"
            
            # B. ìƒëŒ€ ì†ë„ ìœ„ë°˜ (Velocity Surge) - [Phase 3.1] Safety Guard ì ìš©
            # ì›” ì´ˆë°˜(10% ë¯¸ë§Œ)ì—ëŠ” ìš°ì—°ì— ì˜í•œ ë°°ìˆ˜ ë»¥íŠ€ê¸°ê°€ ì‹¬í•˜ë¯€ë¡œ ì†ë„ íŒì • ìŠ¤í‚µ
            elif self.progress_ratio >= self.cfg.MIN_PROGRESS_FOR_VELOCITY:
                expected_current = self.mean * self.progress_ratio
                if expected_current > 0.5 and self.current_value > (expected_current * 4.0):
                    partial_month_penalty = self.cfg.SCORE_PARTIAL_VEL
                    partial_reason = f"ìƒìŠ¹ì„¸ ê°€ì†"
                elif expected_current > 0.5 and self.current_value > (expected_current * 2.5):
                    if self.is_critical:
                        partial_month_penalty = self.cfg.SCORE_PARTIAL_WARN
                        partial_reason = "ìƒìŠ¹ì„¸ ê°€ì†"
        # 2. Main Scoring Variables
        total_score = 0.0
        method_str = ""
        triggered_rules = [] # Nelson Rules Trigger List
        z_score_val = 0.0    # For Safe Zone check

        # 3. Data Scarcity Check (Init)
        if self.n_obs < self.cfg.MIN_DATA_POINTS:
            # ì´ˆê¸° ë°ì´í„° ë¶€ì¡± ì‹œ Rule-based ì²˜ë¦¬
            if self.is_critical:
                if self.current_value >= 2: 
                     return {"score": 100, "status": "ğŸ”´", "reason": f"ì´ˆê¸°ê¸‰ì¦({partial_reason})"}
            else:
                if self.current_value >= 3:
                     return {"score": 50, "status": "ğŸŸ¡", "reason": f"ì´ˆê¸°ì£¼ì˜({partial_reason})"}
                else:
                     return {"score": 0, "status": "âšª", "reason": "ë°ì´í„° ë¶€ì¡±"}

        # 4. Calculation (Dense vs Sparse)
        if self.is_sparse:
            prob_score, method_str = self._calculate_sparse_score()
            
            # Sparse Trend Check
            trend_score = 0
            prev_val = self.history.iloc[-1] if len(self.history) > 0 else 0
            if prev_val > 0 and (self.current_value / prev_val) >= 3.0 and self.current_value >= 3:
                trend_score = 20
            
            total_score = prob_score + trend_score
        else: # Dense
            z_score_val, z_method = self._get_z_score_with_stl()
            method_str = z_method
            
            start_sigma = 0.5 if self.is_critical else 1.0
            base_score = min(50, max(0, (z_score_val - start_sigma) * (50 / 2.0)))
            
            # Apply Nelson Rules
            nelson_score, triggered_rules = self._apply_nelson_rules(z_score_val)
            
            # EWMA Score (Simple Moving Average Deviation)
            ewma = self.series.ewm(alpha=self.cfg.EWMA_LAMBDA, adjust=False).mean()
            z_ewma = (ewma.iloc[-1] - self.mean) / (self.std * np.sqrt(self.cfg.EWMA_LAMBDA/(2-self.cfg.EWMA_LAMBDA)) + 1e-6)
            ewma_score = 15.0 if abs(z_ewma) > 3.0 else 0.0
            
            # Velocity Score
            velocity_score = self._calculate_velocity_score()
            
            total_score = base_score + nelson_score + ewma_score + velocity_score

        # Momentum Score
        momentum_score = self._calculate_momentum_score()
        if momentum_score > 0:
            triggered_rules.append("ì—°ì† ìƒìŠ¹ ëª¨ë©˜í…€")
        total_score += momentum_score

        # 5. Final Aggregation
        total_score += partial_month_penalty
        
        if self.is_critical and total_score > 0:
            total_score += self.cfg.SCORE_CRITICAL_BONUS 
            
        total_score = min(100, total_score)
        
        # [Safe Zone Logic - Phase 3.1 Refined]
        # ì¡°ê±´ë¶€ Safe Zone: ì ìˆ˜ê°€ ì•„ë¬´ë¦¬ ë†’ì•„ë„, 
        # (1) ê±´ìˆ˜ê°€ ì ê³  (2) Z-scoreê°€ ë‚®ìœ¼ë©° (3) **Nelson Rule ìœ„ë°˜ì´ ì—†ì„ ë•Œ**ë§Œ 0ì  ì²˜ë¦¬
        # Sparse ëª¨ë“œì—ì„œëŠ” Z-scoreê°€ ì—†ìœ¼ë¯€ë¡œ ê±´ìˆ˜ ê¸°ì¤€ë§Œ ì ìš©
        if not self.is_sparse:
            # ì•ˆì „ì§€ëŒ€ ì¡°ê±´: ê±´ìˆ˜ 3ê±´ ë¯¸ë§Œ AND ì‹œê·¸ë§ˆ 0.8 ë¯¸ë§Œ
            is_in_safe_range = (self.current_value < 3) and (z_score_val < 0.8)
            # íŒ¨í„´ ìœ„ë°˜ ì—¬ë¶€ (Bias, Trend ë“±)
            has_pattern_issue = len(triggered_rules) > 0
            
            # ë²”ìœ„ëŠ” ì•ˆì „í•˜ì§€ë§Œ íŒ¨í„´ ì´ìŠˆê°€ ìˆë‹¤ë©´ -> ì ìˆ˜ ìœ ì§€ (ê²½ê³ )
            # ë²”ìœ„ë„ ì•ˆì „í•˜ê³  íŒ¨í„´ ì´ìŠˆë„ ì—†ë‹¤ë©´ -> 0ì  (ì•ˆì „)
            if is_in_safe_range and not has_pattern_issue:
                # ë‹¨, ì¡°ê¸° ê³¼ë‹¤(partial_reason)ê°€ ìˆë‹¤ë©´ ë¬´ì‹œ ëª»í•¨
                if not partial_reason:
                    return {"score": 0, "status": "âšª", "reason": "ì •ìƒë²”ì£¼"}

        # [Suppression] 1ê±´ ë…¸ì´ì¦ˆ í•„í„°ë§ (Phase 2.9 Logic - ìˆ˜ì •: ì¼ë°˜ ë“±ê¸‰ ì²« ë°œìƒë„ ì£¼ì˜ ê²½ë³´ë¡œ ì œí•œ)
        if self.current_value == 1:
            is_first_occurrence = (self.mean == 0)
            is_rare_breakout = (self.is_sparse and (len(self.history) > 0 and self.history.iloc[-1] == 0))
            
            if is_first_occurrence or is_rare_breakout:
                # ì¼ë°˜ ë“±ê¸‰ ì²« ë°œìƒì€ ìœ„í—˜ ê²½ë³´ê°€ ì•„ë‹Œ ì£¼ì˜ ê²½ë³´ ìˆ˜ì¤€ìœ¼ë¡œ ì œí•œ
                if not self.is_critical:
                    total_score = min(total_score, self.cfg.THRESHOLD_YEL_GEN - 1)  # 49ì ìœ¼ë¡œ ì œí•œ (ğŸŸ¡)
                # ì¤‘ëŒ€/ìœ„í—˜ ë“±ê¸‰ì€ ê¸°ì¡´ ë¡œì§ ìœ ì§€
            else:
                total_score = min(total_score, 30)
                partial_reason = "" 

        # 6. Status Determination & Text Consolidation (Phase 3.2)
        reason_parts = []
        if partial_reason: reason_parts.append(partial_reason)
        if triggered_rules: reason_parts.extend(triggered_rules)
        if not reason_parts: reason_parts.append(method_str)
        
        # Category-based Text Consolidation
        category_sudden = []      # âš¡ëŒë°œê°ì§€ (í¬ì†Œìœ í˜• ë°œìƒ ê°ì§€, ë¶„í¬ ì´íƒˆ ê°ì§€)
        category_trend = []       # ğŸ“Šì¶”ì„¸ì´íƒˆ (íŒ¨í„´ ì´íƒˆ ê°ì§€, ì •ìƒë²”ìœ„ ì´íƒˆ, í‰ê·  ëŒ€ë¹„ ê¸‰ì¦)
        category_momentum = []    # ğŸ“ˆê¸‰ì¦ê°ì§€ (ì§€ì†ì  ìƒìŠ¹, ì—°ì† ìƒìŠ¹ ëª¨ë©˜í…€, ìƒìŠ¹ì„¸ ê°€ì† ê°ì§€)
        
        for part in reason_parts:
            if any(x in part for x in ["í¬ì†Œìœ í˜• ëŒë°œ ë°œìƒ", "ë¶„í¬ ì´íƒˆ"]):
                category_sudden.append(part)
            elif any(x in part for x in ["ì •ìƒíŒ¨í„´ ì´íƒˆ", "ì •ìƒë²”ìœ„ ì´íƒˆ", "í‰ê·  ëŒ€ë¹„ ê¸‰ì¦"]):
                category_trend.append(part)
            elif any(x in part for x in ["ì§€ì†ì  ìƒìŠ¹", "ì—°ì† ìƒìŠ¹ ëª¨ë©˜í…€", "ìƒìŠ¹ì„¸ ê°€ì†"]):
                category_momentum.append(part)
        
        # Build consolidated reason string
        reason_str = ""
        if category_sudden:
            details = ", ".join(category_sudden)
            reason_str = f"âš¡ëŒë°œê°ì§€({details})"
        if category_trend:
            if reason_str: reason_str += " / "
            details = ", ".join(category_trend)
            reason_str += f"ğŸ“Šì¶”ì„¸ì´íƒˆ({details})"
        if category_momentum:
            if reason_str: reason_str += " / "
            details = ", ".join(category_momentum)
            reason_str += f"ğŸ“ˆê¸‰ì¦ê°ì§€({details})"
        
        # Fallback if nothing was categorized
        if not reason_str:
            reason_str = method_str if method_str else "ì •ìƒë²”ì£¼"
        
        # Thresholds from Config
        thr_red = self.cfg.THRESHOLD_RED_CRIT if self.is_critical else self.cfg.THRESHOLD_RED_GEN
        thr_yel = self.cfg.THRESHOLD_YEL_CRIT if self.is_critical else self.cfg.THRESHOLD_YEL_GEN
        
        final_status = "âšª"
        if total_score >= thr_red:
            final_status = "ğŸ”´"
        elif total_score >= thr_yel:
            final_status = "ğŸŸ¡"

        if self.is_sparse and self.current_value == 2 and self.is_critical and self.mean >= 0.5:
            final_status = "ğŸŸ¡"

        if final_status == "âšª":
             return {"score": int(total_score), "status": "âšª", "reason": "ì •ìƒë²”ì£¼"}
        else:
             return {"score": int(total_score), "status": final_status, "reason": reason_str}


def calculate_lag_stats(df: pd.DataFrame) -> dict:
    """
    Calculate lag statistics from a DataFrame with 'Lag_Days' and 'Lag_Valid' columns.
    Returns dict with count, mean, median (p50), min, max, std.
    """
    if df is None or 'Lag_Days' not in df.columns or 'Lag_Valid' not in df.columns:
        return {'count': 0}
    valid_lag = df[df['Lag_Valid'] == True]['Lag_Days'].dropna()
    if valid_lag.empty:
        return {'count': 0}
    return {
        'count': int(valid_lag.count()),
        'mean': float(valid_lag.mean()),
        'p50': float(valid_lag.median()),
        'min': float(valid_lag.min()),
        'max': float(valid_lag.max()),
        'std': float(valid_lag.std()),
    }

# UI Wrapper
def calculate_advanced_risk_score(history_series: pd.Series, target_month_str: str, grade: str = None) -> Tuple[str, int, str]:
    try:
        if not isinstance(history_series.index, pd.DatetimeIndex):
            history_series.index = pd.to_datetime(history_series.index)
        target_ts = pd.to_datetime(target_month_str)
        
        if target_ts in history_series.index:
            relevant_data = history_series.loc[:target_ts]
        else:
            return "ğŸŸ¢", 0, "ë‹¹ì›”0ê±´"
            
        engine = RiskScoringEngine(relevant_data, grade=grade, target_month_str=target_month_str)
        result = engine.calculate_score()
        return result['status'], result['score'], result['reason']
    except Exception as e:
        return "âšª", 0, f"Err"