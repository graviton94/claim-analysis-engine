# ============================================================================ 
# í˜ì´ì§€: ë§¤ì¶œìˆ˜ëŸ‰ ê´€ë¦¬ (í”¼ë²— í…Œì´ë¸” í˜•íƒœ)
# ============================================================================ 
# ì„¤ëª…: ì—‘ì…€ ìŠ¤íƒ€ì¼ í”¼ë²— í…Œì´ë¸”ë¡œ í”ŒëœíŠ¸ë³„ ë…„/ì›” ë§¤ì¶œìˆ˜ëŸ‰ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
#      í–‰: ID, í”ŒëœíŠ¸ëª…
#      ì—´: [ë…„-ì›”] ì¡°í•©
#      ê°’: ë§¤ì¶œìˆ˜ëŸ‰

import streamlit as st
import pandas as pd
from pathlib import Path
from typing import Optional, Tuple

from core.config import DATA_SALES_PATH, SALES_FILENAME
from core.storage import get_claim_keys

# ============================================================================ 
# í˜ì´ì§€ ë ˆì´ì•„ì›ƒ ì„¤ì •
# ============================================================================ 
st.set_page_config(page_title="ë§¤ì¶œìˆ˜ëŸ‰ ê´€ë¦¬", page_icon="ğŸ’°", layout="wide")
st.title("ğŸ’° ë§¤ì¶œìˆ˜ëŸ‰ ê´€ë¦¬ (í”¼ë²— í…Œì´ë¸”)")
st.markdown(
    "ì—‘ì…€ ìŠ¤íƒ€ì¼ í”¼ë²— í…Œì´ë¸”ë¡œ í”ŒëœíŠ¸ë³„ ë…„/ì›” ë§¤ì¶œìˆ˜ëŸ‰ì„ ê´€ë¦¬í•©ë‹ˆë‹¤. IDë¥¼ í¬í•¨í•˜ì—¬ ìˆ˜ì •, ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n" 
    "- **í–‰**: êµ¬ë¶„ì(ID), í”ŒëœíŠ¸ëª… (í´ë ˆì„ ë°ì´í„° ê¸°ì¤€ ìë™ ì¶”ì¶œ)\n" 
    "- **ì—´**: ë…„-ì›” ì¡°í•© (í´ë ˆì„ ë°ì´í„° ê¸°ì¤€ ìë™ ìƒì„±)\n" 
    "- **ê°’**: ë§¤ì¶œìˆ˜ëŸ‰ (ì§ì ‘ ì…ë ¥)"
)

# ============================================================================ 
# ê¸°ë³¸ ì„¤ì •
# ============================================================================ 
SALES_PATH = Path(DATA_SALES_PATH)
SALES_PATH.mkdir(parents=True, exist_ok=True)
SALES_FILE = SALES_PATH / SALES_FILENAME
BASE_COLUMNS = ['ID', 'í”ŒëœíŠ¸', 'ë…„', 'ì›”', 'ë§¤ì¶œìˆ˜ëŸ‰']


# ============================================================================ 
# ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ (ID ì»¬ëŸ¼ ì¶”ê°€)
# ============================================================================ 
def load_sales_data() -> pd.DataFrame:
    """ì €ì¥ëœ ë§¤ì¶œ ë°ì´í„°(ID í¬í•¨) ë¡œë“œ."""
    if SALES_FILE.exists():
        try:
            df = pd.read_parquet(SALES_FILE)
            if 'ID' not in df.columns:
                df['ID'] = ''  # í•˜ìœ„ í˜¸í™˜ì„±
            return df.sort_values(['í”ŒëœíŠ¸', 'ë…„', 'ì›”']).reset_index(drop=True)
        except Exception as e:
            st.warning(f"ë§¤ì¶œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    return pd.DataFrame(columns=BASE_COLUMNS)

def save_sales_data(df: pd.DataFrame) -> None:
    """ë§¤ì¶œ ë°ì´í„°(ID í¬í•¨) ì €ì¥."""
    try:
        if 'is_estimated' not in df.columns:
            df['is_estimated'] = False
        
        # ìŠ¤í‚¤ë§ˆ ìˆœì„œ ê³ ì •
        df = df.reindex(columns=BASE_COLUMNS + ['is_estimated'], fill_value='')
        df.to_parquet(SALES_FILE, engine='pyarrow', index=False)
        st.success(f"âœ… ë§¤ì¶œ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {len(df)} í–‰")
    except Exception as e:
        st.error(f"âŒ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

def sync_with_claims() -> pd.DataFrame:
    """í´ë ˆì„ ë°ì´í„°ì™€ ë§¤ì¶œ ë°ì´í„° ë™ê¸°í™” (ID í¬í•¨)."""
    try:
        claim_keys = get_claim_keys()
        if claim_keys.empty:
            return load_sales_data()
        
        claim_keys_renamed = claim_keys.rename(columns={'ì ‘ìˆ˜ë…„': 'ë…„', 'ì ‘ìˆ˜ì›”': 'ì›”'})
        sales_df = load_sales_data()

        # IDê°€ ì—†ëŠ” sales_dfì— ID ì»¬ëŸ¼ ì¶”ê°€ (í•˜ìœ„ í˜¸í™˜)
        if 'ID' not in sales_df.columns:
            sales_df['ID'] = ''
        
        # í´ë ˆì„ í‚¤ì˜ í”ŒëœíŠ¸ë³„ë¡œ ê°€ì¥ ìµœì‹  IDë¥¼ ê°€ì ¸ì™€ì„œ ë§¤í•‘ ì¤€ë¹„
        latest_ids = sales_df.sort_values(['ë…„', 'ì›”'], ascending=False).drop_duplicates('í”ŒëœíŠ¸')[['í”ŒëœíŠ¸', 'ID']]
        
        # í´ë ˆì„ í‚¤ì™€ ID ë³‘í•©
        claim_keys_with_id = claim_keys_renamed.merge(latest_ids, on='í”ŒëœíŠ¸', how='left')
        claim_keys_with_id['ID'] = claim_keys_with_id['ID'].fillna('')

        # í´ë ˆì„ í‚¤ ê¸°ì¤€ìœ¼ë¡œ ë§¤ì¶œ ë°ì´í„° ë³‘í•©
        merged = claim_keys_with_id.merge(sales_df.drop(columns='ID'), on=['í”ŒëœíŠ¸', 'ë…„', 'ì›”'], how='left')
        
        merged['ë§¤ì¶œìˆ˜ëŸ‰'] = merged['ë§¤ì¶œìˆ˜ëŸ‰'].fillna(0)
        
        if 'is_estimated' not in merged.columns:
            merged['is_estimated'] = False
        
        return merged.sort_values(['í”ŒëœíŠ¸', 'ë…„', 'ì›”']).reset_index(drop=True)
    
    except Exception as e:
        print(f"[ERROR] Smart Sync ì‹¤íŒ¨: {str(e)}")
        return load_sales_data()

def long_to_pivot(df: pd.DataFrame) -> pd.DataFrame:
    """Long í˜•ì‹ â†’ Pivot í˜•ì‹ ë³€í™˜ (ID í¬í•¨)."""
    if df.empty:
        return pd.DataFrame()
    
    df = df.copy()
    df['ë…„'] = pd.to_numeric(df['ë…„'], errors='coerce').fillna(0).astype(int)
    df['ì›”'] = pd.to_numeric(df['ì›”'], errors='coerce').fillna(0).astype(int)
    df['ë…„ì›”'] = df['ë…„'].astype(str) + '-' + df['ì›”'].astype(str).str.zfill(2)
    
    # 1. ë§¤ì¶œìˆ˜ëŸ‰ í”¼ë²—
    pivot_sales = df.pivot_table(index='í”ŒëœíŠ¸', columns='ë…„ì›”', values='ë§¤ì¶œìˆ˜ëŸ‰', aggfunc='sum', fill_value=0)
    
    # 2. í”ŒëœíŠ¸ë³„ ê³ ìœ  ID ì¶”ì¶œ (ê°€ì¥ ë§ˆì§€ë§‰ ê°’ ì‚¬ìš©)
    id_df = df.sort_values('ë…„ì›”').drop_duplicates('í”ŒëœíŠ¸', keep='last')[['í”ŒëœíŠ¸', 'ID']].set_index('í”ŒëœíŠ¸')
    
    # 3. IDì™€ ë§¤ì¶œìˆ˜ëŸ‰ í”¼ë²— ê²°í•©
    pivot_combined = id_df.join(pivot_sales).reset_index()
    
    # 4. ì»¬ëŸ¼ ìˆœì„œ ì¬ì •ë ¬ (ID, í”ŒëœíŠ¸, ë…„ì›” ìˆœ)
    sorted_yyyymm = sorted([col for col in pivot_combined.columns if col not in ['ID', 'í”ŒëœíŠ¸']])
    display_columns = ['ID', 'í”ŒëœíŠ¸'] + sorted_yyyymm
    pivot_final = pivot_combined.reindex(columns=display_columns)
    
    return pivot_final.fillna({'ID': ''})

def pivot_to_long(pivot_df: pd.DataFrame) -> pd.DataFrame:
    """Pivot í˜•ì‹ â†’ Long í˜•ì‹ ë³€í™˜ (ID í¬í•¨)."""
    if pivot_df.empty:
        return pd.DataFrame(columns=BASE_COLUMNS)
    
    # IDì™€ í”ŒëœíŠ¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ Melt
    long_df = pivot_df.melt(id_vars=['ID', 'í”ŒëœíŠ¸'], var_name='ë…„ì›”', value_name='ë§¤ì¶œìˆ˜ëŸ‰')
    
    long_df[['ë…„', 'ì›”']] = long_df['ë…„ì›”'].str.split('-', expand=True)
    long_df['ë…„'] = pd.to_numeric(long_df['ë…„'], errors='coerce').fillna(0).astype(int)
    long_df['ì›”'] = pd.to_numeric(long_df['ì›”'], errors='coerce').fillna(0).astype(int)
    
    long_df = long_df[BASE_COLUMNS]
    long_df['is_estimated'] = False
    
    return long_df.sort_values(['í”ŒëœíŠ¸', 'ë…„', 'ì›”']).reset_index(drop=True)


# ============================================================================ 
# CSV ì—…ë¡œë“œ í•¨ìˆ˜
# ============================================================================ 
def merge_csv_data(existing_long_df: pd.DataFrame, csv_df: pd.DataFrame) -> pd.DataFrame:
    """CSV ë°ì´í„°ë¥¼ ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•© (ID ë˜ëŠ” í”ŒëœíŠ¸ ê¸°ì¤€)."""
    if csv_df.empty or existing_long_df.empty:
        return existing_long_df
    
    # CSVì˜ í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦
    required_cols = ['ID', 'í”ŒëœíŠ¸', 'ë…„', 'ì›”', 'ë§¤ì¶œìˆ˜ëŸ‰']
    missing = [c for c in required_cols if c not in csv_df.columns]
    if missing:
        st.error(f"CSV ì»¬ëŸ¼ ë¶€ì¡±: {', '.join(missing)}")
        return existing_long_df
    
    # ë°ì´í„° íƒ€ì… ì •ê·œí™”
    csv_df['ë…„'] = pd.to_numeric(csv_df['ë…„'], errors='coerce').fillna(0).astype(int)
    csv_df['ì›”'] = pd.to_numeric(csv_df['ì›”'], errors='coerce').fillna(0).astype(int)
    csv_df['ë§¤ì¶œìˆ˜ëŸ‰'] = pd.to_numeric(csv_df['ë§¤ì¶œìˆ˜ëŸ‰'], errors='coerce').fillna(0)
    
    # CSV ë°ì´í„° ì •ë¦¬
    csv_clean = csv_df[required_cols].copy()
    csv_clean = csv_clean[(csv_clean['ë…„'] > 0) & (csv_clean['ì›”'] > 0)]
    
    if csv_clean.empty:
        st.warning("ìœ íš¨í•œ CSV ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return existing_long_df
    
    # ID ê¸°ì¤€ ë³‘í•© (IDê°€ ìˆìœ¼ë©´ ìš°ì„ )
    result_df = existing_long_df.copy()
    
    for _, row in csv_clean.iterrows():
        csv_id = str(row['ID']).strip() if pd.notna(row['ID']) else ''
        csv_plant = str(row['í”ŒëœíŠ¸']).strip()
        csv_year = int(row['ë…„'])
        csv_month = int(row['ì›”'])
        csv_sales = row['ë§¤ì¶œìˆ˜ëŸ‰']
        
        if csv_id:
            # ID ê¸°ì¤€ ì—…ë°ì´íŠ¸
            mask = (result_df['ID'] == csv_id) & (result_df['ë…„'] == csv_year) & (result_df['ì›”'] == csv_month)
        else:
            # í”ŒëœíŠ¸ ê¸°ì¤€ ì—…ë°ì´íŠ¸
            mask = (result_df['í”ŒëœíŠ¸'] == csv_plant) & (result_df['ë…„'] == csv_year) & (result_df['ì›”'] == csv_month)
        
        if mask.any():
            result_df.loc[mask, 'ë§¤ì¶œìˆ˜ëŸ‰'] = csv_sales
        else:
            # ì‹ ê·œ í–‰ ì¶”ê°€
            new_row = {
                'ID': csv_id,
                'í”ŒëœíŠ¸': csv_plant,
                'ë…„': csv_year,
                'ì›”': csv_month,
                'ë§¤ì¶œìˆ˜ëŸ‰': csv_sales,
                'is_estimated': False
            }
            result_df = pd.concat([result_df, pd.DataFrame([new_row])], ignore_index=True)
    
    return result_df.sort_values(['í”ŒëœíŠ¸', 'ë…„', 'ì›”']).reset_index(drop=True)

# ============================================================================ 
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ============================================================================ 
if 'sales_long_df' not in st.session_state:
    st.session_state.sales_long_df = sync_with_claims()
if 'sales_display_df' not in st.session_state:
    st.session_state.sales_display_df = long_to_pivot(st.session_state.sales_long_df)

# ============================================================================ 
# UI ì˜ì—­
# ============================================================================ 
st.info(
    "ğŸ”„ **Smart Sync í™œì„±í™”**: í´ë ˆì„ ë°ì´í„°ì˜ [í”ŒëœíŠ¸, ë…„, ì›”] ì¡°í•©ì„ ìë™ìœ¼ë¡œ í…Œì´ë¸”ì— ë°˜ì˜í•©ë‹ˆë‹¤.\n\n"
    "- **í–‰(í”ŒëœíŠ¸)**: ì „ì²´ ë°ì´í„° í—ˆë¸Œ(Hub)ì˜ í”ŒëœíŠ¸ unique ê°’\n"
    "- **ì—´(ë…„-ì›”)**: í´ë ˆì„ ë°ì´í„°ì˜ ë…„ì›” ì¡°í•© (ìë™ ì •ë ¬)",
    icon="â„¹ï¸"
)

# CSV ì—…ë¡œë“œ ì„¹ì…˜
with st.expander("ğŸ“¥ CSV ë°ì´í„° ì¼ê´„ ì—…ë¡œë“œ", expanded=False):
    st.markdown("**ë™ì¼ í—¤ë”ì˜ CSV íŒŒì¼**ì„ ì—…ë¡œë“œí•˜ë©´ ID ë˜ëŠ” í”ŒëœíŠ¸ëª…ìœ¼ë¡œ ê¸°ì¡´ ë°ì´í„°ë¥¼ ìë™ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n\n"
                "**CSV ì»¬ëŸ¼**: ID, í”ŒëœíŠ¸, ë…„, ì›”, ë§¤ì¶œìˆ˜ëŸ‰")
    
    uploaded_file = st.file_uploader("CSV íŒŒì¼ ì„ íƒ", type=['csv'], key="csv_uploader")
    
    if uploaded_file is not None:
        try:
            csv_data = pd.read_csv(uploaded_file, encoding='utf-8')
            st.markdown(f"**ë¯¸ë¦¬ë³´ê¸°** ({len(csv_data)}í–‰)")
            st.dataframe(csv_data.head(10), use_container_width=True)
            
            if st.button("âœ… CSV ë°ì´í„° ë³‘í•©", use_container_width=True):
                st.session_state.sales_long_df = merge_csv_data(
                    st.session_state.sales_long_df, 
                    csv_data
                )
                st.session_state.sales_display_df = long_to_pivot(st.session_state.sales_long_df)
                st.success(f"âœ… CSV ë°ì´í„° ë³‘í•© ì™„ë£Œ! ({len(csv_data)}í–‰ ì²˜ë¦¬ë¨)")
                st.rerun()
        except Exception as e:
            st.error(f"âŒ CSV ì½ê¸° ì‹¤íŒ¨: {str(e)}")

st.subheader("ğŸ“Š ë§¤ì¶œìˆ˜ëŸ‰ í”¼ë²— í…Œì´ë¸” (ì—‘ì…€ ìŠ¤íƒ€ì¼)")

if st.session_state.sales_display_df.empty:
    st.warning("âš ï¸ í´ë ˆì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. **[ë°ì´í„° ì—…ë¡œë“œ]** ë©”ë‰´ì—ì„œ ë¨¼ì € ë°ì´í„°ë¥¼ í—ˆë¸Œì— ë¹Œë“œí•˜ì„¸ìš”.")
    st.stop()

st.markdown("ì•„ë˜ í…Œì´ë¸”ì—ì„œ **ID**ì™€ **ë§¤ì¶œìˆ˜ëŸ‰**ì„ ì§ì ‘ ì…ë ¥/ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# í”¼ë²— í…Œì´ë¸” ì—ë””í„° (ID ì»¬ëŸ¼ ì¶”ê°€)
edited_df = st.data_editor(
    st.session_state.sales_display_df,
    use_container_width=True,
    height=400,
    disabled=['í”ŒëœíŠ¸'],  # í”ŒëœíŠ¸ëª…ì€ ìˆ˜ì • ë¶ˆê°€
    num_rows="fixed",
    key="pivot_editor"
)

# ë³€ê²½ì‚¬í•­ ìë™ ë°˜ì˜
if edited_df is not None and not edited_df.equals(st.session_state.sales_display_df):
    st.session_state.sales_display_df = edited_df
    st.session_state.sales_long_df = pivot_to_long(edited_df)

# ì €ì¥ ë²„íŠ¼ ë° í†µê³„
st.subheader("ğŸ’¾ ì €ì¥ ë° í†µê³„")
col_stats1, col_stats2, col_stats3 = st.columns(3)

with col_stats1:
    st.metric("í”ŒëœíŠ¸ ìˆ˜", len(st.session_state.sales_display_df))
with col_stats2:
    period_count = len([c for c in st.session_state.sales_display_df.columns if c not in ['ID', 'í”ŒëœíŠ¸']])
    st.metric("ë…„-ì›” ê¸°ê°„ ìˆ˜", period_count)
with col_stats3:
    total_sales = st.session_state.sales_display_df.drop(columns=['ID', 'í”ŒëœíŠ¸']).sum().sum()
    st.metric("ì´ ë§¤ì¶œìˆ˜ëŸ‰", f"{int(total_sales):,}")

if st.button("ğŸ’¾ ì €ì¥", key="save_sales", use_container_width=True):
    if not st.session_state.sales_long_df.empty:
        save_sales_data(st.session_state.sales_long_df)
    else:
        st.error("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
if not st.session_state.sales_long_df.empty:
    with st.expander("ğŸ“‹ Long í˜•ì‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì €ì¥ í˜•ì‹)", expanded=False):
        st.dataframe(st.session_state.sales_long_df.head(50), use_container_width=True)