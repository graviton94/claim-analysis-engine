import streamlit as st
import pandas as pd
import plotly.express as px
import numpy as np
from datetime import datetime, date
from core.storage import load_partitioned
from core.analytics import detect_outliers_iqr, calculate_lag_stats

# --- 0. ì„¤ì • ë° ìƒìˆ˜ ì •ì˜ ---
st.set_page_config(page_title="í”ŒëœíŠ¸ ë¶„ì„", layout="wide")
st.title("ğŸ­ Phase 2: í”ŒëœíŠ¸ ì •ë°€ ë¶„ì„")

# [CONFIG] ë“±ê¸‰ ê¸°ì¤€ ë§¤í•‘
CRITICAL_GRADES = ['ì¤‘ëŒ€', 'ìœ„í—˜', 'ì‚¬ê³ ']  
GENERAL_GRADES = ['ì¼ë°˜']

# [CONFIG] ë¶ˆë§Œì›ì¸ ê·¸ë£¹ ì •ì˜
PERFORMANCE_REASONS = ['ì œì¡°ë¶ˆë§Œ', 'ê³ ê°ë¶ˆë§Œì¡±', 'êµ¬ë§¤ë¶ˆë§Œ']
TARGET_BUSINESS_UNITS = ['ì‹í’ˆ', 'B2Bì‹í’ˆ']

# --- 1. ë°ì´í„° ë¡œë“œ ---
@st.cache_data
def load_master_data():
    try:
        return load_partitioned()
    except FileNotFoundError:
        return None

master_df = load_master_data()

if master_df is None or master_df.empty:
    st.error("âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    st.stop()

# ë‚ ì§œ ì»¬ëŸ¼ ë³´ì¥
if 'ì ‘ìˆ˜ì¼ì' not in master_df.columns:
    st.error("ë°ì´í„°ì— 'ì ‘ìˆ˜ì¼ì' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()
master_df['ì ‘ìˆ˜ì¼ì'] = pd.to_datetime(master_df['ì ‘ìˆ˜ì¼ì'])

# í”ŒëœíŠ¸ ëª©ë¡ ì¶”ì¶œ
all_plants = sorted(master_df['í”ŒëœíŠ¸'].dropna().unique().tolist())

# --- 2. Step 1: Scope (í”ŒëœíŠ¸ ë° ê¸°ê°„) ---
st.markdown("#### Step 1: ë¶„ì„ ë²”ìœ„ ì„¤ì •")
col_s1_1, col_s1_2, col_s1_3 = st.columns([1, 1, 1])

with col_s1_1:
    selected_plant = st.selectbox("ğŸ­í”ŒëœíŠ¸ ì„ íƒ", all_plants)

# ê¸°ë³¸ ë‚ ì§œ ì„¤ì • (ì „ì²´ ë°ì´í„° ê¸°ì¤€)
min_date = master_df['ì ‘ìˆ˜ì¼ì'].min().date()
max_date = master_df['ì ‘ìˆ˜ì¼ì'].max().date()

with col_s1_2:
    start_date = st.date_input("ğŸ“…ì‹œì‘ì¼ (Start)", value=min_date, min_value=min_date, max_value=max_date)

with col_s1_3:
    end_date = st.date_input("ğŸ“…ì¢…ë£Œì¼ (End)", value=max_date, min_value=min_date, max_value=max_date)

# 1ì°¨ í•„í„°ë§ (í”ŒëœíŠ¸ & ê¸°ê°„)
plant_df = master_df[
    (master_df['í”ŒëœíŠ¸'] == selected_plant) &
    (master_df['ì ‘ìˆ˜ì¼ì'].dt.date >= start_date) &
    (master_df['ì ‘ìˆ˜ì¼ì'].dt.date <= end_date)
].copy()

# Data Summary Badge
if not plant_df.empty:
    st.info(f"ğŸ“‹ **ìš”ì•½**: `{selected_plant}` | `{start_date} ~ {end_date}` | Raw data ì´ **{len(plant_df):,}** ê±´")
else:
    st.warning("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

st.divider()

# --- Step 2 & 3: ê²€ìƒ‰ ì˜µì…˜ ë° ë“±ê¸‰ í•„í„° (2ë‹¨ ë ˆì´ì•„ì›ƒ) ---
col_step2, col_step3 = st.columns(2)

with col_step2:
    st.markdown("#### Step 2: ê²€ìƒ‰ ì˜µì…˜ (Mode)")

    # ê²€ìƒ‰ ëª¨ë“œ ë³€ê²½ ì‹œ Custom ì„ íƒì§€ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” ì½œë°±
    def reset_custom_selections():
        if 'sel_biz' in st.session_state:
            del st.session_state['sel_biz']
        if 'sel_reason' in st.session_state:
            del st.session_state['sel_reason']

    search_mode = st.radio(
        "ì¡°íšŒ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:",
        ("ì¸ì… (Inflow)", "ì‹¤ì  (Performance)", "Custom (ì§ì ‘ ì„ íƒ)"),
        horizontal=True,
        on_change=reset_custom_selections
    )

    filtered_df_step2 = plant_df.copy()

    # ì˜µì…˜ë³„ í•„í„°ë§ ë¡œì§
    if search_mode == "ì¸ì… (Inflow)":
        cond_biz = filtered_df_step2['ì‚¬ì—…ë¶€ë¬¸'].isin(TARGET_BUSINESS_UNITS)
        cond_reason = filtered_df_step2['ë¶ˆë§Œì›ì¸'].notna()
        filtered_df_step2 = filtered_df_step2[cond_biz & cond_reason]
        st.caption(f"â„¹ï¸ **ì¸ì… ê¸°ì¤€**: ì‚¬ì—…ë¶€ë¬¸({', '.join(TARGET_BUSINESS_UNITS)}) + ë¶ˆë§Œì›ì¸(ì „ì²´)")

    elif search_mode == "ì‹¤ì  (Performance)":
        cond_biz = filtered_df_step2['ì‚¬ì—…ë¶€ë¬¸'].isin(TARGET_BUSINESS_UNITS)
        cond_reason = filtered_df_step2['ë¶ˆë§Œì›ì¸'].isin(PERFORMANCE_REASONS)
        filtered_df_step2 = filtered_df_step2[cond_biz & cond_reason]
        st.caption(f"â„¹ï¸ **ì‹¤ì  ê¸°ì¤€**: ì‚¬ì—…ë¶€ë¬¸({', '.join(TARGET_BUSINESS_UNITS)}) + ë¶ˆë§Œì›ì¸({', '.join(PERFORMANCE_REASONS)})")

    else: # Custom
        col_c1, col_c2 = st.columns(2)
        with col_c1:
            opts_biz = sorted(plant_df['ì‚¬ì—…ë¶€ë¬¸'].dropna().unique())
            sel_biz = st.multiselect(
                "ì‚¬ì—…ë¶€ë¬¸ ì„ íƒ", 
                opts_biz, 
                default=opts_biz, 
                key='sel_biz'
            )
        with col_c2:
            opts_reason = sorted(plant_df['ë¶ˆë§Œì›ì¸'].dropna().unique())
            sel_reason = st.multiselect(
                "ë¶ˆë§Œì›ì¸ ì„ íƒ", 
                opts_reason, 
                default=opts_reason, 
                key='sel_reason'
            )
        
        if sel_biz:
            filtered_df_step2 = filtered_df_step2[filtered_df_step2['ì‚¬ì—…ë¶€ë¬¸'].isin(sel_biz)]
        if sel_reason:
            filtered_df_step2 = filtered_df_step2[filtered_df_step2['ë¶ˆë§Œì›ì¸'].isin(sel_reason)]

with col_step3:
    st.markdown("#### Step 3: ë“±ê¸‰ í•„í„° (Grade)")
    grade_mode = st.radio(
        "ë¶„ì„í•  ë“±ê¸‰ì„ ì„ íƒí•˜ì„¸ìš”:",
        ("ì¤‘ëŒ€ (ì¤‘ëŒ€+ìœ„í—˜+ì‚¬ê³ )", "ì¼ë°˜ (ì¼ë°˜)", "ì „ì²´ (All)"),
        horizontal=True
    )

    filtered_df_step3 = filtered_df_step2.copy()

    if grade_mode == "ì¤‘ëŒ€ (ì¤‘ëŒ€+ìœ„í—˜+ì‚¬ê³ )":
        filtered_df_step3 = filtered_df_step3[filtered_df_step3['ë“±ê¸‰ê¸°ì¤€'].isin(CRITICAL_GRADES)]
    elif grade_mode == "ì¼ë°˜ (ì¼ë°˜ ì „ì²´)":
        filtered_df_step3 = filtered_df_step3[~filtered_df_step3['ë“±ê¸‰ê¸°ì¤€'].isin(CRITICAL_GRADES)]
    else:
        pass # ì „ì²´

    cnt_step3 = len(filtered_df_step3)
    st.caption(f"ğŸ“Š í•„í„°ë§ í›„ ëŒ€ìƒ ê±´ìˆ˜: **{cnt_step3:,}** ê±´")

st.divider()

# --- 5. Step 4: Pivot & Analysis (ìƒì„¸ ë¶„ì„) ---
st.markdown("#### Step 4: ìƒì„¸ ë¶„ì„ (Pivot Table)")

col_p1, col_p2 = st.columns([3, 1])

with col_p1:
    # í”¼ë²— ì¸ë±ìŠ¤ ì„¤ì •
    pivot_candidates = ['ì œí’ˆë²”ì£¼1', 'ì œí’ˆë²”ì£¼2', 'ì œí’ˆë²”ì£¼3', 'ëŒ€ë¶„ë¥˜', 'ì¤‘ë¶„ë¥˜', 'ì†Œë¶„ë¥˜', 'ë“±ê¸‰ê¸°ì¤€', 'ë¶ˆë§Œì›ì¸']
    pivot_candidates = [c for c in pivot_candidates if c in filtered_df_step3.columns and filtered_df_step3[c].notna().any()]
    
    default_indices = [c for c in ['ë“±ê¸‰ê¸°ì¤€', 'ëŒ€ë¶„ë¥˜', 'ì¤‘ë¶„ë¥˜'] if c in pivot_candidates]
    
    pivot_indices = st.multiselect(
        "í”¼ë²— í–‰(Index) ì„¤ì •", 
        pivot_candidates, 
        default=default_indices
    )

with col_p2:
    st.markdown("""
    âœ… **í”¼ë²— í–‰ ì„ íƒì§€**
    - `ì œí’ˆë²”ì£¼1, 2, 3`
    - `ëŒ€ë¶„ë¥˜, ì¤‘ë¶„ë¥˜, ì†Œë¶„ë¥˜`
    - `ë“±ê¸‰ê¸°ì¤€`, `ë¶ˆë§Œì›ì¸`
    """)

# ë¶„ì„ ì‹œì‘ ë²„íŠ¼
if st.button("ğŸ“Š ë¶„ì„ ì‹œì‘ (Run Analysis)", type="primary", use_container_width=True):
    
    if not pivot_indices:
        st.error("ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ í”¼ë²— í–‰(Index)ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
        st.stop()
        
    if filtered_df_step3.empty:
        st.warning("ì¡°íšŒ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # --- ë‚ ì§œ/ì›” ì²˜ë¦¬ ---
    # ê·¸ë˜í”„ì˜ ì—°ì†ì„±ì„ ìœ„í•´ ì „ì²´ ê¸°ê°„ì˜ ì›” ëª©ë¡ì„ ìƒì„±
    all_months_in_range = pd.date_range(start=start_date, end=end_date, freq='MS').strftime('%Y-%m').tolist()
    # ì ‘ìˆ˜ì›” ì»¬ëŸ¼ ìƒì„±
    filtered_df_step3['ì ‘ìˆ˜ì›”_str'] = filtered_df_step3['ì ‘ìˆ˜ì¼ì'].dt.strftime('%Y-%m')

    # --- í”¼ë²— í…Œì´ë¸” ìƒì„± ë¡œì§ (ì†Œê³„/ì´ê³„ í¬í•¨) ---
    try:
        def create_pivot_with_subtotals(df, indices, columns, values, aggfunc, all_months):
            """ í”¼ë²— í…Œì´ë¸”ì— ì†Œê³„/ì´ê³„ë¥¼ ì¶”ê°€í•˜ê³ , ëª¨ë“  ì›” ì»¬ëŸ¼ì„ ë³´ì¥ """
            # 1. ê¸°ë³¸ ë§ˆì§„ í”¼ë²— (ì¸ë±ìŠ¤ê°€ 1ê°œì¼ ë•Œ ì•ˆì „ì¥ì¹˜)
            if len(indices) < 2:
                pivot_with_margin = pd.pivot_table(df, index=indices, columns=columns, values=values, aggfunc=aggfunc, fill_value=0, margins=True, margins_name='Total')
                # ëª¨ë“  ì›” í¬í•¨í•˜ë„ë¡ reindex
                pivot_reindexed = pivot_with_margin.reindex(columns=all_months + ['Total'], fill_value=0)
                return pivot_reindexed

            # 2. ê¸°ë³¸ í”¼ë²— ìƒì„±
            pivot_base = pd.pivot_table(df, index=indices, columns=columns, values=values, aggfunc=aggfunc, fill_value=0)
            # ëª¨ë“  ì›” ì»¬ëŸ¼ ë³´ì¥
            pivot_base = pivot_base.reindex(columns=all_months, fill_value=0)
            
            if pivot_base.empty:
                return pivot_base

            all_parts = []
            
            # 3. ì†Œê³„ ê³„ì‚° ë£¨í”„
            for l1_name, l1_group in pivot_base.groupby(level=0, sort=False):
                for l2_name, l2_group in l1_group.groupby(level=1, sort=False):
                    all_parts.append(l2_group)
                    # L2 ì†Œê³„: ('L1 ê°’', 'L2 ê°’', 'ì†Œê³„', '', ..)
                    subtotal_l2_row = l2_group.sum().to_frame().T
                    template_idx = list(l2_group.index[0])
                    idx_tuple = template_idx[:2] + ['ì†Œê³„'] + [''] * (len(indices) - 3)
                    subtotal_l2_row.index = pd.MultiIndex.from_tuples([tuple(idx_tuple)], names=indices)
                    all_parts.append(subtotal_l2_row)
                
                # L1 ì´ê³„: ('L1 ê°’', 'ì „ì²´ í•©ê³„', '', ..)
                total_l1_row = l1_group.sum().to_frame().T
                template_idx = list(l1_group.index[0])
                idx_tuple = [template_idx[0]] + ['ì „ì²´ í•©ê³„'] + [''] * (len(indices) - 2)
                total_l1_row.index = pd.MultiIndex.from_tuples([tuple(idx_tuple)], names=indices)
                all_parts.append(total_l1_row)
            
            final_pivot = pd.concat(all_parts)
            
            # 4. ì „ì²´ ì´ê³„ (Grand Total) ì¶”ê°€
            grand_total_row = pivot_base.sum().to_frame('Total').T
            idx_tuple = ['Total'] + [''] * (len(indices) - 1)
            grand_total_row.index = pd.MultiIndex.from_tuples([tuple(idx_tuple)], names=indices)
            final_pivot = pd.concat([final_pivot, grand_total_row])
            
            # 5. ìš°ì¸¡ Total ì»¬ëŸ¼ ì¶”ê°€
            final_pivot['Total'] = final_pivot.sum(axis=1)

            return final_pivot

        pivot_table = create_pivot_with_subtotals(
            df=filtered_df_step3,
            indices=pivot_indices,
            columns='ì ‘ìˆ˜ì›”_str',
            values='ìƒë‹´ë²ˆí˜¸',
            aggfunc='count',
            all_months=all_months_in_range # ì „ì²´ ì›” ëª©ë¡ ì „ë‹¬
        )

    except Exception as e:
        st.error(f"í”¼ë²— í…Œì´ë¸” ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.exception(e) # ë””ë²„ê¹…ì„ ìœ„í•œ ìƒì„¸ ì˜¤ë¥˜
        st.stop()

    # --- ê²°ê³¼ ì‹œê°í™” ---
    st.subheader(f"ğŸ“ˆ ë¶„ì„ ê²°ê³¼ ({grade_mode} / {search_mode})")
    
    tab1, tab2, tab3 = st.tabs(["í”¼ë²— í…Œì´ë¸”", "Lag ë¶„ì„", "ì›ë³¸ ë°ì´í„°"])

    with tab1:
        # [HOTFIX] ì´ìƒì¹˜ ìŠ¤íƒ€ì¼ë§ ë¡œì§ ì „ë©´ ìˆ˜ì • (Vectorized)
        def highlight_outliers_vectorized(data):
            # 1. ê³„ì‚°ìš© ë°ì´í„° ì¤€ë¹„ (Total í–‰/ì—´ ì œì™¸)
            # errors='ignore'ë¡œ Totalì´ ì—†ì–´ë„ ì—ëŸ¬ë‚˜ì§€ ì•Šê²Œ ì²˜ë¦¬
            df_numeric = data.drop(index='Total', columns='Total', errors='ignore')
            
            # ë§Œì•½ ì¸ë±ìŠ¤ê°€ 'Total'ë¡œ ì‹œì‘í•˜ëŠ” í–‰ì´ ìˆë‹¤ë©´ ê·¸ê²ƒë„ ì œì™¸ (ì†Œê³„/í•©ê³„ í–‰ ì œì™¸)
            # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ Total ì»¬ëŸ¼ë§Œ ì œì™¸í•˜ê³  ê³„ì‚°
            
            # 2. IQR ê³„ì‚° (axis=1: í–‰ ë‹¨ìœ„ ê³„ì‚°)
            q1 = df_numeric.quantile(0.25, axis=1)
            q3 = df_numeric.quantile(0.75, axis=1)
            iqr = q3 - q1
            lower_bound = q1 - 1.5 * iqr
            upper_bound = q3 + 1.5 * iqr

            # 3. ì „ì²´ ë°ì´í„°í”„ë ˆì„ í¬ê¸°ì˜ ìŠ¤íƒ€ì¼ ë§ˆìŠ¤í¬ ìƒì„±
            style_df = pd.DataFrame('', index=data.index, columns=data.columns)
            
            # 4. ì´ìƒì¹˜ ë§ˆí‚¹ (Broadcasting)
            # axis=0ì„ ì‚¬ìš©í•˜ì—¬ Series(í–‰ë³„ ì„ê³„ê°’)ë¥¼ DataFrame ê° í–‰ì— ì ìš©
            # df_numericì— ëŒ€í•´ì„œë§Œ ê³„ì‚°
            is_outlier = (df_numeric.lt(lower_bound, axis=0)) | (df_numeric.gt(upper_bound, axis=0))
            
            # 5. ìŠ¤íƒ€ì¼ ì ìš©
            # is_outlierì˜ Trueì¸ ìœ„ì¹˜ë¥¼ ì°¾ì•„ style_dfì— ì ìš©
            for col in is_outlier.columns:
                # í•´ë‹¹ ì»¬ëŸ¼ì—ì„œ Trueì¸ í–‰ ì¸ë±ìŠ¤ ì¶”ì¶œ
                outlier_indices = is_outlier.index[is_outlier[col]]
                if not outlier_indices.empty:
                    style_df.loc[outlier_indices, col] = 'background-color: #ffcccc'
            
            return style_df

        st.dataframe(
            pivot_table.style.apply(highlight_outliers_vectorized, axis=None).format("{:,}"), 
            use_container_width=True,
            height=600
        )
        st.caption("â€» ë¶‰ì€ìƒ‰ ë°°ê²½: í•´ë‹¹ í–‰(Row) ë‚´ì—ì„œ í†µê³„ì  ì´ìƒì¹˜(IQR 1.5ë°°ìˆ˜ ë²—ì–´ë‚¨) ê°ì§€")

    with tab2:
        st.markdown("##### â±ï¸ Lag ë¶„ì„ (ì œì¡° ~ ì ‘ìˆ˜ ì†Œìš”ê¸°ê°„)")
        lag_stats = calculate_lag_stats(filtered_df_step3)
        
        if lag_stats and lag_stats['count'] > 0:
            c1, c2, c3 = st.columns(3)
            c1.metric("í‰ê·  Lag", f"{lag_stats['mean']:.1f} ì¼")
            c2.metric("ì¤‘ì•™ê°’ Lag", f"{lag_stats['p50']:.1f} ì¼")
            c3.metric("ëŒ€ìƒ ê±´ìˆ˜", f"{lag_stats['count']:,} ê±´")
            
            valid_lag_df = filtered_df_step3[filtered_df_step3['Lag_Valid'] == True]
            fig = px.histogram(
                valid_lag_df, 
                x='Lag_Days', 
                nbins=50,
                title="Lag Days Distribution",
                color_discrete_sequence=['#3b82f6']
            )
            fig.update_layout(xaxis_title="ì†Œìš” ì¼ìˆ˜ (Days)", yaxis_title="ê±´ìˆ˜")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("Lag ë¶„ì„ì„ ìœ„í•œ ìœ íš¨ ë°ì´í„°(ì œì¡°ì¼ì ì¡´ì¬)ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with tab3:
        st.markdown(f"##### ì›ë³¸ ë°ì´í„° ({len(filtered_df_step3):,} ê±´)")
        st.dataframe(filtered_df_step3)